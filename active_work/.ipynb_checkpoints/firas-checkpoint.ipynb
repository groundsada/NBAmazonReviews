{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749d2c71",
   "metadata": {},
   "source": [
    "### \n",
    "### This notebook to configure the preprocessing and cleanup of the dataset\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de62ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Import libraries\n",
    "### \n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import bz2\n",
    "    import re\n",
    "    import os\n",
    "    import gc\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.classify import SklearnClassifier\n",
    "\n",
    "    import os\n",
    "    import shutil\n",
    "    import tarfile\n",
    "    import zipfile\n",
    "\n",
    "except:\n",
    "    print('Error loading required libraries. Please check requirements.txt to make sure you have the required dependencies!')\n",
    "    print('Program will exit. Dependencies required to work.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97170653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded!\n",
      "Error downloading and extracting the dataset.\n",
      "Please make sure you have all the requirements in requirements.txt\n",
      "The program will continue...\n",
      "Please make sure you have the dataset extracted and ready in the \"input\" folder.\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "### Connecting to Kaggle, downloading and extracting the dataset\n",
    "### \n",
    "\n",
    "try: \n",
    "    if os.path.exists('input/test.ft.txt.bz2') and os.path.exists('input/train.ft.txt.bz2'):\n",
    "        print(\"Dataset already downloaded!\")\n",
    "    else:\n",
    "        os.environ['KAGGLE_USERNAME'] = \"mohammadfirassada\"\n",
    "        os.environ['KAGGLE_KEY'] = \"84da0e8dfc70bbf9b3630874156f12f9\"\n",
    "\n",
    "        !kaggle datasets download -d bittlingmayer/amazonreviews\n",
    "        shutil.move('amazonreviews.zip', 'input/amazonreviews.zip')\n",
    "        with zipfile.ZipFile('input/amazonreviews.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('input/')\n",
    "    os.remove('input/amazonreviews.zip')\n",
    "except:\n",
    "    print('Error downloading and extracting the dataset.\\nPlease make sure you have all the requirements in requirements.txt\\nThe program will continue...\\nPlease make sure you have the dataset extracted and ready in the \"input\" folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8833e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the bz2 files. This may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "### Loading the dataset\n",
    "### \n",
    "\n",
    "print('Loading the bz2 files. This may take a few minutes.')\n",
    "\n",
    "train_file = bz2.BZ2File('input/train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('input/test.ft.txt.bz2')\n",
    "\n",
    "\n",
    "train_file_lines = train_file.readlines()\n",
    "test_file_lines = test_file.readlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0564fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 3600000\n",
      "Testing data length: 400000\n",
      "The ratio is: 9:1\n"
     ]
    }
   ],
   "source": [
    "print('Training data length:' ,len(train_file_lines))\n",
    "print('Testing data length:' ,len(test_file_lines))\n",
    "print('The ratio is: ', len(train_file_lines)//len(test_file_lines),':1', sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6563139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### \n",
    "### The assignment asks for a 80/20 split, therefore, we combine the two sets and split them later\n",
    "### \n",
    "\n",
    "dataset = train_file_lines + test_file_lines\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d8f509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d57ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Data preparation: decode and extract labels\n",
    "### \n",
    "\n",
    "dataset = [x.decode('utf-8') for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c220361a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac863a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e17622",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x= dataset_labels)\n",
    "plt.title('Label distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1de08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Data preparation: extract taining data\n",
    "### \n",
    "\n",
    "dataset = [x.split(' ', 1)[1][:-1] for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed74812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8749bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_size = list(map(lambda x: len(x.split()), dataset))\n",
    "sns.histplot(sentences_size)\n",
    "plt.xlabel(\"Num of words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Word Frequency Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Data preparation: cleaning out URLs\n",
    "### \n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    if 'www.' in dataset[i] or 'http:' in dataset[i] or 'https:' in dataset[i] or '.com' in dataset[i]:\n",
    "        dataset[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b633d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(filter(lambda x: '<url>' in x, dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Data preprocessing: lowercasing\n",
    "### \n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the stop words to be removed\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the Porter stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Loop through each document in the dataset\n",
    "for i in range(len(dataset)):\n",
    "    # Lowercase the document\n",
    "    dataset[i] = dataset[i].lower()\n",
    "    \n",
    "    # Tokenize the document into individual words\n",
    "    words = nltk.word_tokenize(dataset[i])\n",
    "    \n",
    "    # Remove the stop words from the list of words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Stem each word using the Porter stemmer\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the list of words back into a single string\n",
    "    dataset[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2786534",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Data preprocessing: removing stop words\n",
    "###\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Data preprocessing: stemming\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
